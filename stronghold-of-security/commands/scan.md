---
name: SOS:scan
description: "Phase 0+0.5: Scan codebase, detect configuration, generate KB manifest, run static pre-scan"
allowed-tools:
  - Read
  - Write
  - Edit
  - Bash
  - Glob
  - Grep
---

# Stronghold of Security — Phase 0 + 0.5: Scan & Pre-Scan

You are starting a comprehensive security audit using Stronghold of Security pipeline.
This command performs the initial codebase scan and static pre-analysis.

## What This Phase Does

1. **Phase 0: Pre-Flight Analysis** — Analyze the codebase to determine audit configuration
2. **Phase 0.5: Static Pre-Scan** — Run grep patterns (+ optional semgrep) to build a hot-spots map

## Arguments

Parse any arguments from the user's message:
- `--tier <quick|standard|deep>` — Override auto-detected tier
- `--batch-size <N>` — Set investigation batch size (default: 5)
- `--strategy-count <N>` — Target strategy count (default: auto per tier)

If no arguments provided, use auto-detection for all settings.

---

## Phase 0: Pre-Flight Analysis

### Step 1: Analyze Codebase

Perform these checks by scanning the codebase:

1. **Count source files and estimate LOC:**
   ```bash
   find . -name '*.rs' -not -path '*/target/*' -not -path '*/.audit/*' | wc -l
   find . -name '*.rs' -not -path '*/target/*' -not -path '*/.audit/*' -exec cat {} + | wc -l
   ```

2. **Detect ecosystem:**
   - Check for `Anchor.toml` or `Cargo.toml` with `anchor-lang` → Solana/Anchor
   - Check for `foundry.toml` or `hardhat.config` → EVM
   - Check for `Move.toml` → Move
   - Default: Solana/Anchor (this skill is Solana-focused)

3. **Identify protocol patterns** by grepping for:
   - AMM/DEX: `swap`, `liquidity`, `pool`, `amm`, `constant_product`
   - Lending: `borrow`, `lend`, `collateral`, `liquidat`, `interest_rate`
   - Staking: `stake`, `unstake`, `delegation`, `validator`, `epoch`
   - Bridge: `bridge`, `relay`, `message`, `guardian`, `vaa`
   - NFT: `metadata`, `mint_nft`, `collection`, `royalt`
   - Oracle: `oracle`, `price_feed`, `switchboard`, `pyth`, `chainlink`
   - Governance: `proposal`, `vote`, `governance`, `timelock`, `quorum`

4. **Detect risk indicators:**
   - Uses external oracles (Pyth, Switchboard imports)
   - Has upgrade mechanism (`upgrade`, `set_authority`, `BpfUpgradeableLoader`)
   - Cross-program calls (`invoke`, `invoke_signed`, CPI contexts)
   - Token transfers/DeFi logic (`transfer`, `Transfer`, `token::`)
   - Token-2022/Extensions (`spl_token_2022`, `transfer_hook`, `TransferFee`)
   - Unsafe blocks (`unsafe {`, `unsafe fn`)

5. **Auto-detect tier** (if not overridden):
   - `quick`: < 10 source files OR < 2,000 LOC
   - `standard`: 10-50 files OR 2,000-20,000 LOC
   - `deep`: > 50 files OR > 20,000 LOC OR complex protocol patterns

6. **Check if codebase builds:**
   ```bash
   # Try anchor build, fall back to cargo build-sbf, fall back to cargo check
   anchor build 2>&1 | tail -5 || cargo build-sbf 2>&1 | tail -5 || cargo check 2>&1 | tail -5
   ```
   Note build status but don't block the audit if it fails.

### Step 2: Generate KB-MANIFEST

Based on detected protocol types and tier, determine which knowledge base files each phase needs.

Write `.audit/KB_MANIFEST.md`:

```markdown
# KB-MANIFEST

Generated by Phase 0 on {date}. This file tells each audit phase which knowledge base files to load.

## Detected Configuration
- **Ecosystem:** {ecosystem}
- **Protocol Types:** {list}
- **Tier:** {tier}
- **Risk Indicators:** {list}

## Phase 1 Agents (Context Building)

### All agents load:
- knowledge-base/core/exploit-patterns-core.md
- knowledge-base/core/exploit-patterns-advanced.md
- knowledge-base/core/secure-patterns.md
- knowledge-base/core/common-false-positives.md
- knowledge-base/solana/solana-runtime-quirks.md
- knowledge-base/solana/anchor-version-gotchas.md
- knowledge-base/solana/known-vulnerable-deps.md

### Tier standard+ adds:
- knowledge-base/core/exploit-patterns-incidents.md

### Tier deep adds:
- knowledge-base/core/exploit-patterns-recent.md

### Conditional:
{- knowledge-base/solana/token-extensions.md (if Token-2022 detected)}

### Protocol playbooks:
{- knowledge-base/protocols/{detected}-attacks.md for each detected protocol}

## Phase 3 (Strategy Generation)
- knowledge-base/core/exploit-patterns-index.md
- knowledge-base/core/exploit-patterns-core.md
- knowledge-base/core/exploit-patterns-advanced.md
- knowledge-base/core/exploit-patterns-incidents.md
- knowledge-base/core/exploit-patterns-recent.md
- knowledge-base/reference/audit-firm-findings.md
- knowledge-base/reference/bug-bounty-findings.md
- {All protocol playbooks from Phase 1}

## Phase 4 Agents (Investigation)
- knowledge-base/core/exploit-patterns-index.md
- Specific exploit-patterns-*.md file(s) based on hypothesis category
- knowledge-base/core/common-false-positives.md
- Relevant protocol playbook (if hypothesis is protocol-specific)

## Phase 5 (Final Synthesis)
- knowledge-base/core/severity-calibration.md
- knowledge-base/core/common-false-positives.md
- knowledge-base/core/exploit-patterns-index.md
```

### Step 3: Present configuration to user

Display the pre-flight analysis results and ask for confirmation:

```markdown
## Pre-Flight Analysis Complete

**Codebase Metrics:**
- Source files: {N}
- Estimated LOC: ~{N}
- Ecosystem: {detected}
- Protocol patterns: {list}

**Risk Indicators:**
- [x/] Uses external oracles
- [x/] Has upgrade mechanism
- [x/] Cross-program calls
- [x/] Token transfers/DeFi logic
- [x/] Token-2022/Extensions
- [x/] Unsafe blocks

**Recommended Configuration:**
- Tier: {tier}
- Batch Size: {N}
- Strategy Count: {N}
- Estimated agents: {N}
- DeFi Economic Model Agent: {Yes/No}

Proceed with these settings? [Y/n/customize]
```

Wait for user confirmation before proceeding.

### Step 4: Model Selection for Phase 1

After user confirms settings, present model selection:

```markdown
### Phase 1 Model Selection

Phase 1 agents analyze the entire codebase through specialized security lenses.
Choose the model for these agents:

  → **Opus** (recommended for deep tier): Maximum novel discovery,
    strongest cross-file reasoning. Higher cost.
  → **Sonnet**: Strong structured analysis guided by KB and hot-spots.
    ~50-60% cheaper. Slightly weaker on novel/creative findings.
```

**Defaults by tier:**
- `deep`: Opus (recommend Opus, user can override to Sonnet)
- `standard`: User choice (present both options equally)
- `quick`: Sonnet (recommend Sonnet, user can override to Opus)

Store choice in STATE.json under `config.models.phase1`.

---

## Phase 0.25: Codebase Indexing

**Goal:** Build a structured INDEX.md for agents to use 3-layer search instead of reading the entire codebase.

### Spawn Indexer Agent

```
Task(
  subagent_type="general-purpose",
  model="haiku",
  prompt="... (see /SOS:index command for full prompt)"
)
```

Use the exact prompt from `stronghold-of-security/commands/index.md` Step 2. The indexer runs on Haiku for cost efficiency — this is mechanical extraction, not reasoning.

After completion, verify `.audit/INDEX.md` was created. Report file count and LOC to user.

---

## Phase 0.5: Static Pre-Scan (Hot-Spots Map)

**Goal:** Build a hot-spots map using pattern-based static analysis. This gives Phase 1 agents concrete leads instead of searching blind.

### Step 1: Check semgrep availability

```bash
which semgrep >/dev/null 2>&1 && echo "SEMGREP_AVAILABLE" || echo "SEMGREP_NOT_AVAILABLE"
```

### Step 2: Run pattern scan

Read the pattern catalog from the skill's resources directory. The file is at the skill installation path — find it with:
```bash
find ~/.claude -name "phase-05-patterns.md" -path "*/stronghold-of-security/*" 2>/dev/null | head -1
```

For each pattern category in the catalog, run the grep commands against the source files. Collect all matches.

If semgrep is available, also run the custom rules:
```bash
# Find the semgrep rules file
RULES_PATH=$(find ~/.claude -name "solana-anchor.yaml" -path "*/stronghold-of-security/*" 2>/dev/null | head -1)
if [ -n "$RULES_PATH" ]; then
  semgrep --config "$RULES_PATH" --json programs/ 2>/dev/null
fi
```

### Step 3: Generate HOT_SPOTS.md

Write `.audit/HOT_SPOTS.md` organized two ways:

1. **By file** — Sorted by risk density (files with most HIGH patterns first)
2. **By focus area** — So each Phase 1 agent can quickly find their relevant hot-spots

Format:
```markdown
# Hot-Spots Map

Generated by Phase 0.5 static pre-scan.

## Summary
- Total patterns matched: {N}
- HIGH risk matches: {N}
- MEDIUM risk matches: {N}
- Files with matches: {N}
- Semgrep: {available/not available}

## By File (Risk Density Order)

### {file_path} — {N} HIGH, {N} MEDIUM
| Line | Pattern | Risk | Focus Area |
|------|---------|------|------------|
| {N} | {pattern_id}: {description} | HIGH | Arithmetic |

### {file_path} — ...

## By Focus Area

### Access Control & Account Validation
| File | Line | Pattern | Risk |
|------|------|---------|------|
| {path} | {N} | {id}: {desc} | HIGH |

### Arithmetic Safety
...

### State Machine & Error Handling
...
{etc. for all 8 focus areas}
```

---

## State Initialization

### Create .audit/ directory structure
```bash
mkdir -p .audit/{context,findings}
```

### Initialize STATE.json

Write `.audit/STATE.json`:
```json
{
  "version": "2.0.0",
  "audit_id": "{generated-uuid}",
  "started_at": "{ISO-8601}",
  "last_updated": "{ISO-8601}",
  "config": {
    "tier": "{tier}",
    "batch_size": {N},
    "strategy_count": {N},
    "ecosystem": "{ecosystem}",
    "protocol_types": ["{list}"],
    "defi_economic_agent": {true/false},
    "models": {
      "index": "haiku",
      "phase1": "{user_choice — opus or sonnet}",
      "quality_gate": "haiku",
      "strategize": "opus",
      "investigate": "sonnet",
      "investigate_tier3": "haiku",
      "coverage": "sonnet",
      "report": "opus",
      "verify": "sonnet"
    }
  },
  "phases": {
    "scan": {
      "status": "completed",
      "completed_at": "{ISO-8601}",
      "files_scanned": {N},
      "loc_estimated": {N},
      "hot_spots_found": {N}
    },
    "analyze": { "status": "pending" },
    "strategize": { "status": "pending" },
    "investigate": { "status": "pending" },
    "report": { "status": "pending" }
  }
}
```

### Initialize PROGRESS.md

Write `.audit/PROGRESS.md`:
```markdown
# Stronghold of Security — Audit Progress

**Audit ID:** {uuid}
**Started:** {date}
**Tier:** {tier}
**Codebase:** {directory name}

## Phase Progress

| Phase | Command | Status | Output |
|-------|---------|--------|--------|
| Scan | `/SOS:scan` | Completed | KB_MANIFEST.md, HOT_SPOTS.md |
| Analyze | `/SOS:analyze` | Pending | — |
| Strategize | `/SOS:strategize` | Pending | — |
| Investigate | `/SOS:investigate` | Pending | — |
| Report | `/SOS:report` | Pending | — |

## Last Updated
{timestamp}
```

---

## Phase Complete — Present Results

After all Phase 0 + 0.5 work is done, present this to the user:

```markdown
---

## Phase 0 + 0.5 Complete

### What was produced:
- `.audit/INDEX.md` — Structured codebase index ({N} files, {N} LOC)
- `.audit/KB_MANIFEST.md` — Knowledge base loading manifest for all phases
- `.audit/HOT_SPOTS.md` — Static pre-scan results ({N} patterns found across {N} files)
- `.audit/STATE.json` — Audit state tracking
- `.audit/PROGRESS.md` — Human-readable progress

### Hot-Spots Summary:
- {N} HIGH risk patterns found
- {N} MEDIUM risk patterns found
- Top files by risk density: {top 3 files}

### Configuration:
- Tier: {tier}
- Focus areas: {N} (+ Economic Model: {yes/no})
- Target strategies: {N}

### Next Step:
Run **`/clear`** then **`/SOS:analyze`** to deploy {N} parallel context auditors.
(`/clear` gives the next phase a fresh context window — critical for quality.)

---
```
